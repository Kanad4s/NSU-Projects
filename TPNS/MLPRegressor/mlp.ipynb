{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.005000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>584.576000</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>2.959000</td>\n",
       "      <td>2.662000</td>\n",
       "      <td>1.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.431441</td>\n",
       "      <td>10.988665</td>\n",
       "      <td>313.438517</td>\n",
       "      <td>1.379086</td>\n",
       "      <td>1.423849</td>\n",
       "      <td>1.719509</td>\n",
       "      <td>1.404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processor_Speed     RAM_Size  Storage_Capacity  Screen_Size  \\\n",
       "count      1000.000000  1000.000000       1000.000000  1000.000000   \n",
       "mean          3.005000    15.500000        584.576000     3.055000   \n",
       "std           1.431441    10.988665        313.438517     1.379086   \n",
       "min           1.000000     4.000000        256.000000     1.000000   \n",
       "25%           2.000000     8.000000        256.000000     2.000000   \n",
       "50%           3.000000    16.000000        512.000000     3.000000   \n",
       "75%           4.000000    32.000000       1000.000000     4.000000   \n",
       "max           5.000000    32.000000       1000.000000     5.000000   \n",
       "\n",
       "            Weight        Price        Brand  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      2.959000     2.662000     1.956000  \n",
       "std       1.423849     1.719509     1.404292  \n",
       "min       1.000000     1.000000     0.000000  \n",
       "25%       2.000000     1.000000     1.000000  \n",
       "50%       3.000000     2.000000     2.000000  \n",
       "75%       4.000000     5.000000     3.000000  \n",
       "max       5.000000     5.000000     4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>167891.703087</td>\n",
       "      <td>200.946368</td>\n",
       "      <td>11.065946</td>\n",
       "      <td>0.916420</td>\n",
       "      <td>2.650302</td>\n",
       "      <td>1.883713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Storage_Capacity    RAM_Size  Processor_Speed  Screen_Size  \\\n",
       "0           0          1.000000    0.013188         0.007079     0.004808   \n",
       "1           1     167891.703087  200.946368        11.065946     0.916420   \n",
       "\n",
       "      Brand    Weight  \n",
       "0  0.004771  0.003309  \n",
       "1  2.650302  1.883713  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "dataSet = pd.read_csv('../base/processed_laptop.csv')\n",
    "display(dataSet.describe())\n",
    "gainRation = pd.read_csv('../base/gr_laptop.csv')\n",
    "display(gainRation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        2.662000\n",
       "std         1.719509\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.005000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>584.576000</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>2.959000</td>\n",
       "      <td>1.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.431441</td>\n",
       "      <td>10.988665</td>\n",
       "      <td>313.438517</td>\n",
       "      <td>1.379086</td>\n",
       "      <td>1.423849</td>\n",
       "      <td>1.404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processor_Speed     RAM_Size  Storage_Capacity  Screen_Size  \\\n",
       "count      1000.000000  1000.000000       1000.000000  1000.000000   \n",
       "mean          3.005000    15.500000        584.576000     3.055000   \n",
       "std           1.431441    10.988665        313.438517     1.379086   \n",
       "min           1.000000     4.000000        256.000000     1.000000   \n",
       "25%           2.000000     8.000000        256.000000     2.000000   \n",
       "50%           3.000000    16.000000        512.000000     3.000000   \n",
       "75%           4.000000    32.000000       1000.000000     4.000000   \n",
       "max           5.000000    32.000000       1000.000000     5.000000   \n",
       "\n",
       "            Weight        Brand  \n",
       "count  1000.000000  1000.000000  \n",
       "mean      2.959000     1.956000  \n",
       "std       1.423849     1.404292  \n",
       "min       1.000000     0.000000  \n",
       "25%       2.000000     1.000000  \n",
       "50%       3.000000     2.000000  \n",
       "75%       4.000000     3.000000  \n",
       "max       5.000000     4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dataSet.drop(['Price'], axis=1)\n",
    "y = dataSet['Price']\n",
    "display(y.describe())\n",
    "display(x.describe())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=55, shuffle=True)\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.02\n",
      "R² Score: 0.9935752776684683\n",
      "200\n",
      "1 -1.0\n",
      "2 1.0\n",
      "74 -1.0\n",
      "130 -1.0\n",
      "Mean Squared Error (MSE): 0.03582511155627449\n",
      "R² Score: 0.9884916802877394\n",
      "200\n",
      "0 0.28417687428371297\n",
      "1 -0.7050013703828628\n",
      "2 0.29561214189653784\n",
      "3 -0.15972295173045103\n",
      "4 -0.09160133230702616\n",
      "5 -0.12136102565146079\n",
      "6 -0.0755696167961668\n",
      "7 -0.09350428481534756\n",
      "8 -0.11549712100472354\n",
      "9 0.23512630871457496\n",
      "10 -0.08270881905175376\n",
      "11 -0.14454884104626764\n",
      "12 -0.07715430151230773\n",
      "13 0.2776823399408679\n",
      "14 -0.12004380045750884\n",
      "15 -0.07919213724917196\n",
      "16 -0.13457198361586298\n",
      "17 0.27423392749493836\n",
      "18 -0.13741908293386973\n",
      "19 -0.08106995539731265\n",
      "20 0.24811808020683568\n",
      "21 -0.07854741713471114\n",
      "22 0.2536074792695917\n",
      "23 -0.06773488615612866\n",
      "24 -0.10114007105680911\n",
      "25 -0.14719256799073266\n",
      "26 0.2652682788195033\n",
      "27 -0.15681216113547047\n",
      "28 -0.09730527156675972\n",
      "29 -0.08793877553579321\n",
      "30 -0.10411300533184353\n",
      "31 -0.15416843419100568\n",
      "32 -0.08676587771357358\n",
      "33 -0.14582728953507895\n",
      "34 -0.09043645142827827\n",
      "35 -0.12855143204871133\n",
      "36 -0.15145494249468716\n",
      "37 0.24307002888499873\n",
      "38 0.2371302338098089\n",
      "39 0.27423392749493836\n",
      "40 -0.09936929897046087\n",
      "41 0.25710731564553146\n",
      "42 -0.0974062441536736\n",
      "43 0.2542041461223503\n",
      "44 -0.122847492788978\n",
      "45 -0.05930961433993076\n",
      "46 -0.07179491961458506\n",
      "47 -0.11126595433582831\n",
      "48 -0.07614309275733877\n",
      "49 0.23014337586942712\n",
      "50 -0.13658805566085608\n",
      "51 -0.1333137512220024\n",
      "52 0.26022927576918065\n",
      "53 -0.05074630841522776\n",
      "54 -0.1320837518665654\n",
      "55 0.23414630779466572\n",
      "56 -0.14469631929796178\n",
      "57 -0.08035862141096128\n",
      "58 -0.06943549761894996\n",
      "59 0.2908372277000959\n",
      "60 -0.09337210439337529\n",
      "61 -0.10090270986130356\n",
      "62 -0.0763293999158936\n",
      "63 -0.1514717879213292\n",
      "64 -0.11994282787059607\n",
      "65 -0.09253035737031823\n",
      "66 -0.13751708072414703\n",
      "67 -0.1540876776990434\n",
      "68 -0.13432198518033545\n",
      "69 -0.08425135639444559\n",
      "70 -0.12714692881452572\n",
      "71 0.25694884565372833\n",
      "72 -0.09724920136158488\n",
      "73 -0.06351591863871242\n",
      "74 -0.7127941212360778\n",
      "75 0.28961020314129504\n",
      "76 -0.07588507737833883\n",
      "77 -0.13657436111417653\n",
      "78 -0.13009081851144044\n",
      "79 0.2679168718274778\n",
      "80 -0.05714136556636085\n",
      "81 0.27104684889460007\n",
      "82 -0.11480749850852456\n",
      "83 -0.07009430815176287\n",
      "84 -0.09249914953525806\n",
      "85 -0.08002901820871866\n",
      "86 -0.11731319134448359\n",
      "87 -0.09407896818788863\n",
      "88 0.2555896406729543\n",
      "89 -0.06716330146183136\n",
      "90 -0.12729319965485053\n",
      "91 -0.07073902826622369\n",
      "92 -0.1554917850615558\n",
      "93 -0.08450742830485236\n",
      "94 -0.0540221604510025\n",
      "95 0.2532222017338479\n",
      "96 -0.08312038615732753\n",
      "97 -0.13528789568189237\n",
      "98 -0.13934374693234264\n",
      "99 -0.1485407812313977\n",
      "100 -0.06976510082119347\n",
      "101 -0.07866098474477567\n",
      "102 -0.16027769099810674\n",
      "103 -0.10423605930196711\n",
      "104 -0.07563662653973058\n",
      "105 0.2629956867907106\n",
      "106 0.23987493334118692\n",
      "107 0.24608024446997145\n",
      "108 -0.08090197306683589\n",
      "109 -0.07840451696269568\n",
      "110 0.24505219028836134\n",
      "111 0.2881237360037776\n",
      "112 0.25739162059436227\n",
      "113 -0.06224548709337263\n",
      "114 -0.08540861620139228\n",
      "115 -0.13491378596958392\n",
      "116 -0.07941550592931801\n",
      "117 -0.1385919807560898\n",
      "118 0.2610371121506079\n",
      "119 -0.12879827960427614\n",
      "120 -0.056311817694782995\n",
      "121 -0.11217486120716114\n",
      "122 -0.11994282787059607\n",
      "123 -0.13514202071324033\n",
      "124 0.27510688235305514\n",
      "125 0.2822290193936534\n",
      "126 -0.09046131379839384\n",
      "127 0.25636317054107893\n",
      "128 -0.0982943989385181\n",
      "129 0.2791239046966463\n",
      "130 -0.7039713727326582\n",
      "131 -0.13888235917980007\n",
      "132 -0.133809445487848\n",
      "133 -0.14917788027405798\n",
      "134 0.2641841544327179\n",
      "135 0.2561612253672525\n",
      "136 0.24861692535264446\n",
      "137 -0.10219485289679486\n",
      "138 -0.13267240177585116\n",
      "139 -0.10491619543810682\n",
      "140 -0.10048015101562058\n",
      "141 -0.05776707699724071\n",
      "142 -0.7178270508115205\n",
      "143 -0.06669079808757239\n",
      "144 -0.0815127303379457\n",
      "145 -0.11170872927646225\n",
      "146 -0.13813059300354769\n",
      "147 -0.1384910081691768\n",
      "148 -0.09965360391929168\n",
      "149 -0.042252767242378475\n",
      "150 -0.043125722100493924\n",
      "151 0.25659140528473534\n",
      "152 -0.08972053936225066\n",
      "153 -0.09538210296348826\n",
      "154 0.23461376902208775\n",
      "155 0.2422343553368207\n",
      "156 0.2567125939665993\n",
      "157 -0.08661077839007802\n",
      "158 -0.10075479352106509\n",
      "159 -0.05349100794660622\n",
      "160 -0.08817800201955883\n",
      "161 0.23780886456589911\n",
      "162 -0.09997368479801239\n",
      "163 -0.1448221542549899\n",
      "164 -0.1228025904072394\n",
      "165 0.24036261066355946\n",
      "166 -0.06833155300888816\n",
      "167 -0.15301117438405787\n",
      "168 0.25087377147832335\n",
      "169 -0.11098369075858372\n",
      "170 -0.12773557872381147\n",
      "171 -0.07698781457703152\n",
      "172 -0.15383922686043605\n",
      "173 -0.04755883394321714\n",
      "174 -0.09406323226962288\n",
      "175 0.23758670329712217\n",
      "176 -0.1360678948965688\n",
      "177 0.2511843659969837\n",
      "178 -0.15904432097436105\n",
      "179 0.25568259631639556\n",
      "180 -0.11742636308287469\n",
      "181 -0.060170370046570554\n",
      "182 -0.14413887722373575\n",
      "183 -0.04012157999040156\n",
      "184 -0.10967851461139788\n",
      "185 0.2489910350649529\n",
      "186 -0.14282314742498525\n",
      "187 -0.0618149113042179\n",
      "188 0.28145703712245007\n",
      "189 -0.11177849402831574\n",
      "190 -0.07835961458095753\n",
      "191 -0.11247015789610071\n",
      "192 -0.10947656943757167\n",
      "193 0.2814692362739275\n",
      "194 -0.13448807624393821\n",
      "195 -0.0953760294886088\n",
      "196 0.25638338663602944\n",
      "197 -0.06834839843552931\n",
      "198 -0.08876980280880797\n",
      "199 -0.1370308306014898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)  # Среднеквадратичная ошибка\n",
    "r2 = r2_score(y_test, y_pred)  # Коэффициент детерминации R²\n",
    "\n",
    "# матрица ошибок\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "print(len(y_test))\n",
    "for i, lable in enumerate(y_test):\n",
    "    if y_pred[i] -  lable != 0:\n",
    "        print(i, y_pred[i] -  lable)\n",
    "# for i in range(len(y_test)):\n",
    "#     print(y_pred[i] -  y_test.at[i])\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)  # Среднеквадратичная ошибка\n",
    "r2 = r2_score(y_test, y_pred)  # Коэффициент детерминации R²\n",
    "\n",
    "# матрица ошибок\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "print(len(y_test))\n",
    "for i, lable in enumerate(y_test):\n",
    "    if y_pred[i] -  lable != 0:\n",
    "        print(i, y_pred[i] -  lable)\n",
    "# for i in range(len(y_test)):\n",
    "#     print(y_pred[i] -  y_test.at[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собственная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (800, 800) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Один выход (регрессия)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MLPRegressor(input_size, hidden_size, output_size)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Предсказание\u001b[39;00m\n\u001b[1;32m     69\u001b[0m predictions \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(x_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "Cell \u001b[0;32mIn[40], line 42\u001b[0m, in \u001b[0;36mMLPRegressor.train\u001b[0;34m(self, X, y, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     41\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     44\u001b[0m         loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msquare(y \u001b[38;5;241m-\u001b[39m output))\n",
      "Cell \u001b[0;32mIn[40], line 27\u001b[0m, in \u001b[0;36mMLPRegressor.backward\u001b[0;34m(self, X, y, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, learning_rate):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Обратное распространение ошибки\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\n\u001b[1;32m     28\u001b[0m     d_output \u001b[38;5;241m=\u001b[39m error  \u001b[38;5;66;03m# Производная для линейной активации (просто ошибка)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     error_hidden \u001b[38;5;241m=\u001b[39m d_output\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_hidden_output\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/base.py:1383\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:5915\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   5912\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   5914\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 5915\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5916\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5918\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   5919\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/construction.py:658\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    655\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[1;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 658\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/construction.py:717\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    719\u001b[0m     )\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (800, 800) instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPRegressor:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Инициализация весов и смещений\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.bias_hidden = np.zeros(hidden_size)\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias_output = np.zeros(output_size)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Прямое распространение\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = self.output_input  # Линейная активация на выходном слое\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # Обратное распространение ошибки\n",
    "        error = y - self.output\n",
    "        d_output = error  # Производная для линейной активации (просто ошибка)\n",
    "\n",
    "        error_hidden = d_output.dot(self.weights_hidden_output.T)\n",
    "        d_hidden = error_hidden * self.sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        # Обновление весов и смещений\n",
    "        self.weights_hidden_output += self.hidden_output.T.dot(d_output) * learning_rate\n",
    "        self.bias_output += np.sum(d_output, axis=0) * learning_rate\n",
    "        self.weights_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
    "        self.bias_hidden += np.sum(d_hidden, axis=0) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean(np.square(y - output))\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример данных с 6 целочисленными атрибутами\n",
    "    np.random.seed(42)\n",
    "    # X = np.random.randint(0, 10, size=(100, 6))  # 100 samples, 6 features\n",
    "    # y = np.random.randint(0, 10, size=(100, 1))  # 100 targets (целевые значения)\n",
    "\n",
    "    # Нормализация данных (опционально, но рекомендуется для улучшения обучения)\n",
    "    X = x_train.astype(np.float32) / 1000.0  # Нормализация к диапазону [0, 1]\n",
    "    y = y_train.astype(np.float32) / 1000.0  # Нормализация к диапазону [0, 1]\n",
    "\n",
    "    # Создание и обучение сети\n",
    "    input_size = X.shape[1]  # Количество входных признаков (6)\n",
    "    hidden_size = 10  # Количество нейронов в скрытом слое\n",
    "    output_size = 1  # Один выход (регрессия)\n",
    "    mlp = MLPRegressor(input_size, hidden_size, output_size)\n",
    "    mlp.train(X, y, epochs=10000, learning_rate=0.01)\n",
    "\n",
    "    # Предсказание\n",
    "    predictions = mlp.predict(x_test.values)\n",
    "    print(\"Predictions:\")\n",
    "    print(predictions * 10)  # Возвращаем значения к исходному масштабу\n",
    "\n",
    "    # Оценка качества модели (среднеквадратичная ошибка)\n",
    "    mse = np.mean(np.square(y_test - predictions))\n",
    "    print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, input_size, activation='sigmoid'):\n",
    "        self.weights = np.random.randn(input_size + 1) * 0.1  # +1 для смещения (bias)\n",
    "        self.activation_function = self._get_activation_function(activation)\n",
    "        self.activation_derivative = self._get_activation_derivative(activation)\n",
    "    \n",
    "    def _get_activation_function(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif activation == 'tanh':\n",
    "            return np.tanh\n",
    "        elif activation == 'relu':\n",
    "            return lambda x: np.maximum(0, x)\n",
    "    \n",
    "    def _get_activation_derivative(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return lambda x: x * (1 - x)\n",
    "        elif activation == 'tanh':\n",
    "            return lambda x: 1 - np.tanh(x)**2\n",
    "        elif activation == 'relu':\n",
    "            return lambda x: np.where(x > 0, 1, 0)\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        z = np.dot(inputs, self.weights[:-1]) + self.weights[-1]\n",
    "        return self.activation_function(z)\n",
    "\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, num_neurons, input_size):\n",
    "        self.neurons = [Neuron(input_size) for _ in range(num_neurons)]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return np.array([neuron.activate(inputs) for neuron in self.neurons])\n",
    "    \n",
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        # обратное распространение ошибки (подробности ниже)\n",
    "        pass\n",
    "\n",
    "input_size = 3  # количество входов\n",
    "hidden_size = 5  # количество нейронов в скрытом слое\n",
    "output_size = 1  # количество выходов\n",
    "\n",
    "layer1 = Layer(hidden_size, input_size)\n",
    "layer2 = Layer(output_size, hidden_size)\n",
    "\n",
    "network = Network([layer1, layer2])\n",
    "\n",
    "# Пример входных данных\n",
    "X = np.array([0.5, 0.1, 0.4])\n",
    "output = network.forward(X)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков: [2.62875]\n",
      "\n",
      "Предсказания цен ноутбуков [[2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]\n",
      " [2.62875]]\n",
      "Ожидаемые результаты: 458    2\n",
      "387    3\n",
      "532    2\n",
      "895    1\n",
      "239    5\n",
      "      ..\n",
      "681    5\n",
      "570    2\n",
      "227    5\n",
      "638    5\n",
      "979    1\n",
      "Name: Price, Length: 200, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MLPRegressor:\n",
    "    def __init__(self, layers, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = layers\n",
    "        \n",
    "        # Инициализация весов и смещений случайными значениями\n",
    "        self.weights = [np.random.randn(layers[i], layers[i+1]) * 0.1 for i in range(len(layers)-1)]\n",
    "        self.biases = [np.zeros((1, layers[i+1])) for i in range(len(layers)-1)]\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Прямое распространение\"\"\"\n",
    "        self.activations = [X]\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            X = self.relu(np.dot(X, self.weights[i]) + self.biases[i])\n",
    "            self.activations.append(X)\n",
    "        \n",
    "        X = np.dot(X, self.weights[-1]) + self.biases[-1]  # Линейный выход\n",
    "        self.activations.append(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        \"\"\"Обратное распространение ошибки\"\"\"\n",
    "        m = X.shape[0]\n",
    "        output_error = self.activations[-1] - y  # Градиент MSE\n",
    "        errors = [output_error]\n",
    "\n",
    "        for i in range(len(self.weights) - 1, 0, -1):\n",
    "            error = errors[-1].dot(self.weights[i].T) * self.relu_derivative(self.activations[i])\n",
    "            errors.append(error)\n",
    "        errors.reverse()\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.activations[i].T.dot(errors[i]) * self.learning_rate\n",
    "            self.biases[i] -= np.sum(errors[i], axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for _ in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "X = x_train.values\n",
    "y = y_train.values.reshape(-1, 1)\n",
    "# print(y)\n",
    "\n",
    "mlp = MLPRegressor(layers=[6, 16, 8, 1], learning_rate=0.0001)  # 6 входов, два скрытых слоя, 1 выход\n",
    "mlp.train(X, y, epochs=1000)\n",
    "\n",
    "predictions = mlp.predict(x_test)\n",
    "for pred in predictions:\n",
    "    print(f\"Предсказания цен ноутбуков: {pred}\\n\")\n",
    "print(\"Предсказания цен ноутбуков:\\b\",  predictions)\n",
    "print(f\"Ожидаемые результаты: {y_test}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
