{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.005000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>584.576000</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>2.959000</td>\n",
       "      <td>2.662000</td>\n",
       "      <td>1.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.431441</td>\n",
       "      <td>10.988665</td>\n",
       "      <td>313.438517</td>\n",
       "      <td>1.379086</td>\n",
       "      <td>1.423849</td>\n",
       "      <td>1.719509</td>\n",
       "      <td>1.404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processor_Speed     RAM_Size  Storage_Capacity  Screen_Size  \\\n",
       "count      1000.000000  1000.000000       1000.000000  1000.000000   \n",
       "mean          3.005000    15.500000        584.576000     3.055000   \n",
       "std           1.431441    10.988665        313.438517     1.379086   \n",
       "min           1.000000     4.000000        256.000000     1.000000   \n",
       "25%           2.000000     8.000000        256.000000     2.000000   \n",
       "50%           3.000000    16.000000        512.000000     3.000000   \n",
       "75%           4.000000    32.000000       1000.000000     4.000000   \n",
       "max           5.000000    32.000000       1000.000000     5.000000   \n",
       "\n",
       "            Weight        Price        Brand  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      2.959000     2.662000     1.956000  \n",
       "std       1.423849     1.719509     1.404292  \n",
       "min       1.000000     1.000000     0.000000  \n",
       "25%       2.000000     1.000000     1.000000  \n",
       "50%       3.000000     2.000000     2.000000  \n",
       "75%       4.000000     5.000000     3.000000  \n",
       "max       5.000000     5.000000     4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>167891.703087</td>\n",
       "      <td>200.946368</td>\n",
       "      <td>11.065946</td>\n",
       "      <td>0.916420</td>\n",
       "      <td>2.650302</td>\n",
       "      <td>1.883713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Storage_Capacity    RAM_Size  Processor_Speed  Screen_Size  \\\n",
       "0           0          1.000000    0.013188         0.007079     0.004808   \n",
       "1           1     167891.703087  200.946368        11.065946     0.916420   \n",
       "\n",
       "      Brand    Weight  \n",
       "0  0.004771  0.003309  \n",
       "1  2.650302  1.883713  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "dataSet = pd.read_csv('../base/Processed_laptop.csv')\n",
    "display(dataSet.describe())\n",
    "gainRation = pd.read_csv('../base/Laptop_gr.csv')\n",
    "display(gainRation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        2.662000\n",
       "std         1.719509\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processor_Speed</th>\n",
       "      <th>RAM_Size</th>\n",
       "      <th>Storage_Capacity</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.005000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>584.576000</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>2.959000</td>\n",
       "      <td>1.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.431441</td>\n",
       "      <td>10.988665</td>\n",
       "      <td>313.438517</td>\n",
       "      <td>1.379086</td>\n",
       "      <td>1.423849</td>\n",
       "      <td>1.404292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processor_Speed     RAM_Size  Storage_Capacity  Screen_Size  \\\n",
       "count      1000.000000  1000.000000       1000.000000  1000.000000   \n",
       "mean          3.005000    15.500000        584.576000     3.055000   \n",
       "std           1.431441    10.988665        313.438517     1.379086   \n",
       "min           1.000000     4.000000        256.000000     1.000000   \n",
       "25%           2.000000     8.000000        256.000000     2.000000   \n",
       "50%           3.000000    16.000000        512.000000     3.000000   \n",
       "75%           4.000000    32.000000       1000.000000     4.000000   \n",
       "max           5.000000    32.000000       1000.000000     5.000000   \n",
       "\n",
       "            Weight        Brand  \n",
       "count  1000.000000  1000.000000  \n",
       "mean      2.959000     1.956000  \n",
       "std       1.423849     1.404292  \n",
       "min       1.000000     0.000000  \n",
       "25%       2.000000     1.000000  \n",
       "50%       3.000000     2.000000  \n",
       "75%       4.000000     3.000000  \n",
       "max       5.000000     4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dataSet.drop(['Price'], axis=1)\n",
    "y = dataSet['Price']\n",
    "display(y.describe())\n",
    "display(x.describe())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.017922923468160826\n",
      "Mean Absolute Error (MAE): 0.0851329664020592\n",
      "Mean Absolute Percentage Error (MAPE): 0.05165152791909047\n",
      "R² Score: 0.9940516665666056\n",
      "\n",
      "\n",
      "0 0.0857514764279399\n",
      "1 -0.018954686796577747\n",
      "2 -0.10721036276829232\n",
      "3 0.15626582665144007\n",
      "4 -0.022854846955860708\n",
      "5 -0.015205538474230451\n",
      "6 -0.08226780171709835\n",
      "7 0.10199982910840433\n",
      "8 -0.8674442473012531\n",
      "9 -0.06306436020638273\n",
      "10 -0.09593126862311019\n",
      "11 -0.07855785009514271\n",
      "12 0.07433391866422845\n",
      "13 0.17307207612786213\n",
      "14 -0.17090419425900572\n",
      "15 0.07615826762550615\n",
      "16 -0.013409010608350869\n",
      "17 -0.0482108481386625\n",
      "18 0.16745525810752837\n",
      "19 -0.10239116789268721\n",
      "20 -0.024432946186387028\n",
      "21 -0.027777445327825\n",
      "22 0.007405696340017531\n",
      "23 -0.054930391714431925\n",
      "24 -0.0572013460455818\n",
      "25 0.024505799484147772\n",
      "26 0.11653356623997135\n",
      "27 0.2945355628593145\n",
      "28 0.12371675087603018\n",
      "29 0.02751394757803105\n",
      "30 0.015500723171550934\n",
      "31 0.01939856388022676\n",
      "32 0.11654601261393438\n",
      "33 0.08382692696459593\n",
      "34 0.04585330004825927\n",
      "35 0.04282601372544681\n",
      "36 0.10041642558345032\n",
      "37 0.07615826762550615\n",
      "38 -0.13536558365235685\n",
      "39 -0.045898632520363414\n",
      "40 -0.08535589826825074\n",
      "41 -0.039813375411262175\n",
      "42 0.14942370121906912\n",
      "43 0.006970536669804517\n",
      "44 0.13577942317543235\n",
      "45 0.028022746139251264\n",
      "46 0.022204581914722965\n",
      "47 -0.02475269896275667\n",
      "48 -0.16194136846400897\n",
      "49 -0.1583991927927908\n",
      "50 -0.02994449583702119\n",
      "51 -0.09567125573196122\n",
      "52 -0.035241542324572106\n",
      "53 -0.0365223682568222\n",
      "54 -0.00505675489370816\n",
      "55 -0.034376614378896164\n",
      "56 -0.03131722950688243\n",
      "57 0.061150413880259435\n",
      "58 -0.0650722907913166\n",
      "59 -0.09272781099404881\n",
      "60 -0.030918224109621972\n",
      "61 -0.032773499039395304\n",
      "62 -0.009667024547820091\n",
      "63 -0.07980692029605874\n",
      "64 -0.016750901523447714\n",
      "65 0.06976341815686027\n",
      "66 0.03142861812752962\n",
      "67 -0.08822335084795263\n",
      "68 0.057354284063020344\n",
      "69 0.22360573899698855\n",
      "70 0.08428998848588698\n",
      "71 0.014163111430374187\n",
      "72 -0.08175265096158357\n",
      "73 0.018430870184802828\n",
      "74 -0.05281469688974916\n",
      "75 -0.04679439360361215\n",
      "76 0.04254750926269546\n",
      "77 0.003868442488984325\n",
      "78 0.07806627043612124\n",
      "79 -0.09537537978108501\n",
      "80 0.028333895382599117\n",
      "81 0.028694827209466922\n",
      "82 -0.025498929437829387\n",
      "83 -0.17488347803799853\n",
      "84 -0.04610599546026595\n",
      "85 -0.020944706446854422\n",
      "86 0.052482355062877684\n",
      "87 0.5536010450782443\n",
      "88 -0.10498284013774106\n",
      "89 -0.04812515748151469\n",
      "90 -0.11519952153177315\n",
      "91 0.01201453486342885\n",
      "92 -0.03479374956116743\n",
      "93 -0.15292137681011486\n",
      "94 -0.10964814845211879\n",
      "95 -0.06859872748112761\n",
      "96 0.06294974997516611\n",
      "97 0.03505307105828681\n",
      "98 -0.08607001330103747\n",
      "99 -0.1726017256901119\n",
      "100 0.15499723265887955\n",
      "101 -0.06836748720297348\n",
      "102 0.07530902350800472\n",
      "103 0.05064780177376127\n",
      "104 -0.11226659060525701\n",
      "105 0.09362541090219656\n",
      "106 0.06478951572454328\n",
      "107 0.06692682373785086\n",
      "108 0.0646310169872315\n",
      "109 -0.0990007084672484\n",
      "110 -0.011713368730587481\n",
      "111 -0.044369645629075194\n",
      "112 0.009408176949145641\n",
      "113 -0.10870718284300374\n",
      "114 -0.04415059424897905\n",
      "115 0.10179098447306956\n",
      "116 0.14378074148553122\n",
      "117 0.08088669657901804\n",
      "118 -0.07010013868868092\n",
      "119 -0.04430175828444227\n",
      "120 -0.07525916070310679\n",
      "121 0.028944024968069026\n",
      "122 -0.016610336533890435\n",
      "123 -0.053290793487819954\n",
      "124 -0.06846503122948178\n",
      "125 -0.0334251151576338\n",
      "126 0.07678609660813152\n",
      "127 0.2350018571059307\n",
      "128 -0.07186172980595629\n",
      "129 0.029445206517841216\n",
      "130 0.1373962488710525\n",
      "131 0.15512061769372165\n",
      "132 -0.17599593779885903\n",
      "133 0.0885710507142452\n",
      "134 -0.041913706737181755\n",
      "135 -0.07679602990060941\n",
      "136 0.04125547082768133\n",
      "137 0.17117211825539158\n",
      "138 0.03122850588378867\n",
      "139 0.044737582172388324\n",
      "140 -0.0007017303355922877\n",
      "141 0.03951896861854465\n",
      "142 0.0874104407821843\n",
      "143 0.059858357188790734\n",
      "144 -0.18600356106199067\n",
      "145 0.03763524774550664\n",
      "146 -0.026648100664516505\n",
      "147 -0.01603549278335592\n",
      "148 -0.08233303134130487\n",
      "149 -0.02498372212144495\n",
      "150 0.21036902728852103\n",
      "151 0.01901503561493101\n",
      "152 0.058080022189389346\n",
      "153 -0.10259675426968651\n",
      "154 0.2119290793015718\n",
      "155 0.17251671475217112\n",
      "156 0.0547830813569401\n",
      "157 0.06584545222047855\n",
      "158 0.11721081795385313\n",
      "159 -0.18312933576164192\n",
      "160 -0.05412258063746833\n",
      "161 0.0029899496908134537\n",
      "162 -0.11902675662719764\n",
      "163 -0.013698342040620037\n",
      "164 0.001904956399403801\n",
      "165 0.1524676461723793\n",
      "166 -0.07714030169140562\n",
      "167 0.04656433004052962\n",
      "168 -0.06637551356054416\n",
      "169 0.0067246293801623835\n",
      "170 -0.012072535345700852\n",
      "171 0.22616243552503845\n",
      "172 -0.8835478163005739\n",
      "173 0.04153355816131388\n",
      "174 -0.03954394158467944\n",
      "175 0.0937574187517729\n",
      "176 0.14057567548851702\n",
      "177 0.00413235533169809\n",
      "178 -0.07377581999811555\n",
      "179 0.03336785136806775\n",
      "180 0.006712400680433994\n",
      "181 0.1465724775965902\n",
      "182 -0.03550087718721784\n",
      "183 0.007109764951177766\n",
      "184 0.039000808245673646\n",
      "185 -0.016946425013090072\n",
      "186 -0.07488960879988715\n",
      "187 -0.05116413446345547\n",
      "188 -0.10077597586554887\n",
      "189 0.12352921565159658\n",
      "190 0.022056723232800834\n",
      "191 -0.18703933247615956\n",
      "192 0.20642893992856504\n",
      "193 -0.10094953589292932\n",
      "194 -0.02180984887263193\n",
      "195 0.15193989718734535\n",
      "196 -0.005855233661313242\n",
      "197 0.005791331691187951\n",
      "198 0.2057705539069996\n",
      "199 0.15418410691340867\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "df = pd.read_csv(\"../base/Processed_laptop.csv\")\n",
    "\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# print(X_test_scaled)\n",
    "\n",
    "hiddenLayers = (64, 32)\n",
    "learningRate = 0.002\n",
    "maxIter = 1000\n",
    "randomState = 42\n",
    "\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=hiddenLayers, \n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    max_iter=maxIter, \n",
    "    random_state=randomState, \n",
    "    learning_rate_init=learningRate\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# матрица ошибок\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)  # Среднеквадратичная ошибка\n",
    "mae = mean_absolute_error(y_test, y_pred)  # Средняя абсолютная ошибка\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) # Средняя абсолютная процентная ошибка\n",
    "r2 = r2_score(y_test, y_pred)  # Коэффициент детерминации R²\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"R² Score: {r2}\\n\\n\")\n",
    "\n",
    "# for i, lable in enumerate(y_test):\n",
    "#     if y_pred[i] -  lable != 0:\n",
    "        # print(i, y_pred[i] -  lable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собственная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.052521487216191896\n",
      "Mean Absolute Error (MAE): 0.1713920597233409\n",
      "Mean Absolute Percentage Error (MAPE): 0.11111138672034353\n",
      "R² Score: 0.9825689531657789\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPRegressor:\n",
    "    def __init__(self, hidden_layer_sizes=(100,), activation='relu', \n",
    "                 learning_rate=0.001, max_iter=200, random_state=42):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "    def _initialize_weights(self, n_features, n_outputs):\n",
    "        np.random.seed(self.random_state)\n",
    "        layer_sizes = [n_features] + list(self.hidden_layer_sizes) + [n_outputs]\n",
    "        \n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            limit = np.sqrt(6 / (layer_sizes[i] + layer_sizes[i+1]))\n",
    "            self.weights.append(np.random.uniform(-limit, limit, \n",
    "                                               (layer_sizes[i], layer_sizes[i+1])))\n",
    "            self.biases.append(np.zeros(layer_sizes[i+1]))\n",
    "    \n",
    "    def _activation(self, x):\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        return x\n",
    "    \n",
    "    def _activation_derivative(self, x):\n",
    "        if self.activation == 'relu':\n",
    "            return (x > 0).astype(float)\n",
    "        return np.ones_like(x)\n",
    "    \n",
    "    def _forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        zs = []\n",
    "        \n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(activations[-1], w) + b\n",
    "            a = self._activation(z)\n",
    "            zs.append(z)\n",
    "            activations.append(a)\n",
    "            \n",
    "        return activations, zs\n",
    "    \n",
    "    def _backprop(self, X, y, activations, zs):\n",
    "        gradients_w = [np.zeros_like(w) for w in self.weights]\n",
    "        gradients_b = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        delta = (activations[-1] - y) * self._activation_derivative(zs[-1])\n",
    "        gradients_b[-1] = np.mean(delta, axis=0)\n",
    "        gradients_w[-1] = np.dot(activations[-2].T, delta) / len(X)\n",
    "        \n",
    "        for l in range(len(self.weights)-2, -1, -1):\n",
    "            delta = np.dot(delta, self.weights[l+1].T) * self._activation_derivative(zs[l])\n",
    "            gradients_b[l] = np.mean(delta, axis=0)\n",
    "            gradients_w[l] = np.dot(activations[l].T, delta) / len(X)\n",
    "            \n",
    "        return gradients_w, gradients_b\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1] if len(X.shape) > 1 else 1\n",
    "        n_outputs = y.shape[1] if len(y.shape) > 1 else 1\n",
    "        \n",
    "        X = np.array(X).reshape(n_samples, n_features)\n",
    "        y = np.array(y).reshape(n_samples, n_outputs)\n",
    "        \n",
    "        self._initialize_weights(n_features, n_outputs)\n",
    "        \n",
    "        for _ in range(self.max_iter):\n",
    "            activations, zs = self._forward_pass(X)\n",
    "            gradients_w, gradients_b = self._backprop(X, y, activations, zs)\n",
    "            \n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] -= self.learning_rate * gradients_w[i]\n",
    "                self.biases[i] -= self.learning_rate * gradients_b[i]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        activations, _ = self._forward_pass(X)\n",
    "        return activations[-1].squeeze()\n",
    "\n",
    "df = pd.read_csv(\"../base/Processed_laptop.csv\")\n",
    "\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=hiddenLayers, \n",
    "    activation='relu', \n",
    "    learning_rate=learningRate, \n",
    "    max_iter=maxIter,\n",
    "    random_state=randomState\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)  # Среднеквадратичная ошибка\n",
    "mae = mean_absolute_error(y_test, y_pred)  # Средняя абсолютная ошибка\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) # Средняя абсолютная процентная ошибка\n",
    "r2 = r2_score(y_test, y_pred)  # Коэффициент детерминации R²\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"R² Score: {r2}\\n\\n\")\n",
    "\n",
    "# for i, lable in enumerate(y_test):\n",
    "#     if y_pred[i] -  lable != 0:\n",
    "        # print(i, y_pred[i] -  lable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
