## 7.1
1. ИИ — это способность решать задачи самостоятельно, без полного программирования.
2. Знания могут быть заложены вручную, но это не всегда возможно.
2. Обучение — ключевой способ получения и улучшения знаний в ИИ.
2. Машинное обучение позволяет системе извлекать закономерности из данных.
2. Мощные ИИ-системы сочетают предопределенные алгоритмы, знания и обучение.
2. Примеры, как шахматы или AlphaGo, иллюстрируют, насколько обучение усиливает ИИ.


## 7.2 What category of problems does machine learning solve?
### 7.2.1
1. Предсказательные функции — основа многих ML-задач.
2. Обучение проводится на паре "вход — правильный ответ" (обучение с учителем).
2. Выход может быть дискретным (классификация) или непрерывным (регрессия).
2. Предсказательная модель может быть реализована по-разному: деревья решений, правила, нейросети и т. д.
2. Цель — создать модель, хорошо работающую и на новых данных.
### 7.2.2
1. Описательные модели помогают понять структуру данных, а не предсказывать.
2. Примеры задач: кластеризация, снижение размерности, оценка плотности.
2. Эти подходы часто используются при отсутствии размеченных данных.
2. Метод полезен в бизнесе, визуализации, обнаружении аномалий и подготовке признаков.
2. Это фундаментальная часть обучения без учителя в машинном обучении.
## 7.3 From data to model: an overview
### 7.3.1 From data to model
1. Машинное обучение — это процесс, охватывающий этапы от данных до внедрения модели.
2. Ключевые этапы: сбор, подготовка, обучение, оценка, развертывание.
2. Каждое решение на каждом этапе влияет на финальный результат.
2. Тип задачи (с учителем / без учителя / с подкреплением) определяет выбор подхода.
### 7.3.2 Data Collection and Preparation
1. Без качественных и подходящих данных модель не будет работать хорошо.
1. Сбор данных — это не только поиск, но и разметка, проверка, чистка.
1. Предобработка включает в себя масштабирование, удаление пропусков, извлечение признаков.
1. В реальных задачах этот этап самый долгий и важный.
### 7.3.3 Format of the Data
1. Стандартный формат — таблица: строки = примеры, столбцы = признаки.
1. Признаки могут быть разного типа: числовые, категориальные, текстовые, порядковые.
1. Категориальные и текстовые данные требуют дополнительного кодирования.
1. Некоторые данные (например, изображения, графы) требуют специального представления.
### 7.3.4
1. Машинное обучение охватывает широкий спектр подходов, и существует несколько классификаций и точек зрения на эту область.
1. Алгоритмы машинного обучения могут классифицировать задачи и данные по различным признакам, таким как тип задачи, тип данных, формат выходных данных.
1. Пример с фильтрацией спама показывает, как можно использовать модели для предсказания результата (например, спам или не-спам) на основе различных входных данных (простых или сложных признаков).
1. Методы машинного обучения могут быть представлены различными форматами, включая математические модели или правила "если-то".
1. Каждая парадигма машинного обучения имеет несколько алгоритмов с гиперпараметрами, влияющими на их поведение.
### 7.3.5
### 7.3.6
### 7.3.7
### 7.3.8
### 7.3.9
### 7.3.10
### 7.3.11
### 7.3.12
### 7.3.13
### 7.3.14
PGM используются для моделирования популяции с помощью её совместного распределения вероятностей (Joint Probability Distribution, JPD).
Когда JPD известна, с ней можно производить всевозможные виды рассуждений (см. главу 6). Здесь же речь идет о том, как такие распределения можно извлекать из данных
* JPD - Совместные распределения вероятностей
* JPD — это функция, которая возвращает вероятность того, что случайно выбранный экземпляр из популяции будет равен конкретному x.
* Пример: если в банке 10 жёлтых, 5 красных и 5 зелёных шариков, вероятность вытащить красный: p(красный) = 5/20.

Факторизация JPD(СРВ)
* Полное JPD можно представить в виде таблицы всех возможных комбинаций переменных, но это неэффективно при большом числе переменных.
* Вместо этого используют факторизацию: JPD представляется как произведение меньших функций.

Баис наивный
* Используется для классификации. Предполагается, что все признаки X независимы между собой при условии класса Y.
У нас 20 шариков с размерами, цветом и материалом. Хотим оценить вероятность "большой, белый, стеклянный".
Если мы примем независимость признаков, то:
P(big) × P(white) × P(glass) = (5/20) × (4/20) × (15/20) = 3/80 = 0.0375

Если ослабить предположения и учитывать зависимость цвета и размера от материала:
P(big|glass) × P(white|glass) × P(glass) = (4/15) × (2/15) × (15/20) = 0.027

Предсказание класса:
Если мы знаем, что шарик большой и белый, можем вычислить:

P(glass | big, white) = 0.027 / (0.027 + 0.02) = 0.57

P(agate | big, white) = 0.43
→ предсказывается класс glass.

* **JPD описывает вероятность каждой комбинации признаков объекта.**
* **Факторизация JPD нужна для работы с большим числом признаков.**
* **Наивный Байес использует предположение независимости признаков при фиксированном классе → прост в реализации.**


* Bayesian networks (Байесовские сети)
  * Направленные графы: узлы — переменные, стрелки — зависимости.
  * У каждой переменной — распределение условное на её родителях.
  * Удобно интерпретировать в терминах причинности, но причинность не гарантируется.

* Markov random fields (MRFs) / Markov networks
  * Ненаправленные графы.
  * Каждому клике (полносвязной группе узлов) соответствует функция-потенциал.
  * JPD = произведение всех потенциалов.

* Factor graphs
  * Двухтиповые графы: переменные и факторы.
  * Узлы-факторы соединены с соответствующими переменными.
* Dynamic Bayesian Networks 
  * Моделируют последовательные процессы.

  * Значения переменных в момент времени t зависят от переменных как в момент t, так и в момент t−1.

  * Применяются, например, в обработке естественного языка (NLP).
* **PGM позволяет гибко и компактно моделировать зависимости между переменными через графы.**
* **Преимущество PGM — возможность задавать и использовать структуру зависимостей, повышая точность и эффективность модели.**
### 7.3.15 Clustering and density estimation
**Кластеризация** — это вид обучения без учителя, как и матричная факторизация: мы пытаемся найти структуру в данных.

Базовая кластеризация — это группировка похожих объектов. Бывают:
* Иерархические кластеры (вложенные),
* Концептуальные кластеры (дополнительно описываются).


**Простая (плоская) кластеризация**  
🔹 Основная идея:
* Разделение набора данных на группы похожих объектов — кластеры. На визуализации пространства данных кластеры выглядят как "острова плотности" — области с высокой концентрацией объектов.
  * К средних
  * Гаусовские смеси
  * Спектральная

**Иерархическая кластеризация**
Основная идея:
* Похожа на таксономии (например, классификация животных):

  * Есть общий класс (млекопитающие),
  * Подклассы (собаки),
  * Подподклассы (овчарки, хаски и т.д.).

🔹 Два подхода:
* Top-down: делим весь набор данных на подгруппы.

* Bottom-up: объединяем близкие объекты в группы.

🔹 Результат — дендрограмма:
Графическое представление иерархии кластеров.

Можно "обрезать" на нужной высоте для получения плоской кластеризации.

**Полуобученная кластеризация (Semi-supervised)**
* Понятие "сходства" субъективно.

  * Например, что означает «похожи» для фото людей? Одежда? Поза? Внешность?
* Полуобученные методы позволяют пользователю вносить примеры, какие объекты должны быть вместе (или раздельно).

  * На основе этих подсказок алгоритм строит функцию сходства, соответствующую пользовательским ожиданиям.

* Constraint-based clustering: пользователь указывает пары объектов, которые (не)должны быть в одном кластере.


| Метод                | Тип             | Принцип                               | Преимущества                              | Ограничения                              |
|----------------------|------------------|----------------------------------------|-------------------------------------------|-------------------------------------------|
| k-means              | Плоская          | Делит на k кластеров по центрам       | Прост, быстрый                            | Только сферические кластеры, чувствителен к инициализации |
| EM                   | Плоская, вероятн.| Смесь распределений, EM-итерации      | Учет вероятностей, гибкость               | Медленный, чувствителен к инициализации   |
| Спектральная         | Плоская, графовая| Кластеры по структуре графа           | Сложные формы кластеров                   | Дорогой, нужна мера сходства              |
| Иерархическая        | Иерархическая    | Снизу вверх или сверху вниз           | Вложенность, не требует k                 | Дорогая, выбор уровня обрезки             |
| Полуобученная (COBRAS)| Полуобученная   | Учитывает пользовательские подсказки  | Субъективность, интерактивность           | Требует участия, зависит от подсказок     |

### 7.3.17 Подкрепляющее обучение (Reinforcement Learning, RL)
Это обобщённая форма обучения, при которой агент действует в среде, получая награды за действия, и его цель — максимизировать суммарную награду.
Определение задачи RL:

*   Агент может находиться в различных состояниях.

*   Он может выполнять действия, которые приводят к новым состояниям и наградам.

*   Цель — найти стратегию (политику) π: S → A, которая максимизирует суммарную дисконтированную награду:

*   Где γ — дисконт-фактор, уменьшающий вес будущих наград.

*   Пример — игра в шахматы: состояния — позиции на доске, действия — ходы, награды — победа (+1), поражение (−1), ничья (0). Оптимальная стратегия — это умение хорошо играть.

Различие между краткосрочной и долгосрочной выгодой — важно не максимизировать мгновенную награду, а уметь планировать наперёд.
* Варианты сложности:
  * Простая среда: агент знает функции переходов и наград. Можно просто просчитать всё наперёд.
  * Сложная среда: агент не знает переходов и наград. Он должен их исследовать.

Агент может выяснить это, просто попробовав. Такой агент может сначала узнать все, что можно знать об окружающей среде, исследуя (пробуя каждое действие в каждом возможном состоянии и наблюдая, к какому состоянию оно приводит и какова его непосредственная награда), а затем изучить оптимальную политику, описанную ранее. На практике алгоритмы обучения с подкреплением объединяют эти две фазы (изучение окружающей среды и поиск оптимальной политики) в одну.

* Q-learning
  * Q-обучение изучает функцию Q(s,a), которая представляет «качество» выполнения действия a в состоянии s, где качество определяется как накопленное вознаграждение, которое мы получим, если предпримем действие a в состоянии s, и после этого последовательно выберем действие с наибольшим Q-значением
  * Особенности Q-обучения:
    * Агент исследует случайные действия.
    * Он не строит модель среды, а только таблицу Q-значений.
    * Это позволяет сэкономить ресурсы — не нужно знать, к какому состоянию приводит действие, достаточно знать, какое действие лучше.
  * Стратегия исследования
    * Нам не интересна вся функция Q. Нам важен сам план и его лучшие действия, а на сколько плохи остальные знать не обязательно.
    * Однорукие бандиты(игровые автоматы) - их много, у всех разный шанс выиграша, но вам неизвестно что и шанс может быть разным. Какая стратегия будет лучшая, если есть много времени. В моменте можете упасть в локальный минимум. Через время вы определитесь с одним автоматом. Если ждать слишком долго, то не максимизируете прибыль. **Балансировать исследование и использование лучших вариантов.**
    * Играем на прибыль в перспективе, а не в моменте
    * Важно, что план надо строить для того, чтобы использовать. В обучении с подкреплением есть фаза обучения, а во время использования применяется изученный план и идет дополнительно обучение, что корректирует лучший план
    * Метод поиска по дереву монте карло. В шахматах в определенный момент есть много ходов. Спрогнозировать все ходы - сложно, их много. Поэтому прогнозируются ходы, которые чаще приводили к победе. Изначально выборка случайна, но потом выборка случается.


До сих пор мы предполагали, что Q-значения хранятся в таблице, которая содержит одну строку для каждого состояния и один столбец для каждого действия. Это работает, если состояний и действий не слишком много. Но если мы рассмотрим случай, когда состояние определяется значениями ряда переменных, мы легко можем получить огромное количество состояний. Она может быть даже бесконечной, если некоторые переменные непрерывны. Q-обучение сходится только в том случае, если каждая пара действий 306 H.Blockeel встречалась много раз. Очевидно, что это условие нереально в очень больших пространствах состояний. В таком случае, имеет смысл хранить текущее приближение Q-функции не как подлежащее, а с использованием другого формата: нейронная сеть, ансамбль дерева решений, линейная модель и т.д. Конечно, Q-обновления больше не могут быть выполнены путем простого обновления значения в atable. Вместо этого следует следующая процедура: генерируем большое количество значений Q(s,a) в обычном; как только их достаточно, изучите модель, которая по заданному S, A-паре предсказывает Q; используйте эти предсказания в правой части уравнения Беллмана, показанного ранее; сохранить результат вычисления правой части в качестве целевого значения для нового обучающего экземпляра для Q(s,A). Как только у нас будет достаточное количество новых обучающих экземпляров, мы обучим модель. Таким образом, генерация данных с использованием старой версии Q-модели и обучение новой модели на основе этих данных чередуются, и это продолжается до тех пор, пока не будет получена хорошая аппроксимация Q-функции

### 7.3.18
* Hyperparameter tuning (K-средних, функция ядра svm, скорость обучения)
  * выбрать 100 параметров - выучить 100 моделей
  * нельзя ориентироваться на тестовые значения
  * При малом числе параметров — grid search (перебор по сетке).
  * При большом — используются более умные методы:
  * AutoML — автоматический выбор алгоритма и его параметров.
  * Часто применяют байесовскую оптимизацию.
  * Современные AutoML-системы также настраивают предобработку данных, отбор признаков и т.п.
* Missing data and noise
  * Если пропусков мало — можно игнорировать такие примеры.
  * При множестве признаков и частых пропусках это не работает.
  * Некоторые методы умеют работать с пропусками:
  * Например, деревья могут игнорировать примеры при оценке конкретного признака.
  * Методы, не умеющие обрабатывать пропуски, используют импутацию:
    * Замена пропусков на среднее/случайное значение.
    * Это добавляет шум в данные.
    * Методы, устойчивые к шуму, работают лучше при этом подходе.
  * Происхождение пропусков:
    * MCAR (полностью случайные пропуски) — независимы от всех переменных.
    * MAR (пропуски случайны, но могут зависеть от целевой переменной).
    * NMAR (не случайные пропуски) — могут зависеть от всего, без ограничений.
  * Методы могут быть устойчивыми к пропускам, но не всегда для всех случаев
  * Про шум (ошибочные значения):
    * Некоторые алгоритмы чувствительны даже к одному выбросу.
    * Устойчивость к шуму связана с устойчивостью к переобучению.
    * Но не всегда: линейная регрессия может недообучаться, но при этом сильно чувствительна к выбросам.
* Integrating background knowledge (Интеграция фоновых знаний)
  * Лучшие результаты достигаются при объединении данных и знаний из предметной области.
  * Некоторые подходы (например, индуктивное логическое программирование) позволяют вводить знания в систему.
  * Архитектура модели может отражать структуру знаний (например, в PGM или нейросетях).
  * чаще всего требуется сотрудничество экспертов в ML и области. Это требует усилий, но окупается в большинстве случаев.
* Передача обучения (Transfer learning)
  * модель обучается на одном датасете, а потом переносится в другую задачу, где ее адаптируют.
    * Предложить бегуну остановиться, данные у всех уникальные, но есть сходства у всех людей.
    * Комьютерное зрение - сначала распознают функции, которые полезны для широкого спектра задач зрения
## 7.4 Evaluating the results Оценка результатов
Когда для задачи подходит несколько методов машинного обучения, возникает вопрос: какой из них выбрать?
Лучшая по ресурсам, времени, устойчивости к шуму, точности предсказания
* Точность - модель, предсказывающая “нет” всегда, может иметь 99.9999% точности — но она бесполезна, если цель — находить террористов.
* Cost of Errors:
  * FP (False Positive) – ложная тревога,
  * FN (False Negative) – пропущенная угроза.
  * Error = CFP ⋅ FPR ⋅ P(Neg) + CFN ⋅ FNR ⋅ P(Pos)
  * CFP, CFN — стоимость ложных срабатываний,
  * FPR — доля отрицательных, предсказанных как положительные,
  * FNR — доля положительных, предсказанных как отрицательные.  
* ROC-диаграмма и AUC  
ROC (Receiver Operating Characteristics) — график:
X: FPR (ложные срабатывания),
Y: TPR = 1 - FNR (верные тревоги).
Идеальная модель — в левом верхнем углу (0,1).
AUC (Area Under the Curve) — мера качества модели.
📌 ROC помогает выбрать модель, оптимальную для условий: цены ошибок и распределения классов.

* Ошибки
* В регрессии предсказания редко бывают точными. Используются метрики:
  * MAE (средняя абсолютная ошибка),
  * MSE (среднеквадратичная ошибка),
  * RMSE — корень из MSE
* Кластерицазия
  * Внутриклассовая дисперсия, но для систем с большим кол-вом кластеров это неоч
  * В некоторых случаях имеется референциальная кластеризация Ris, с которой можно сравнить построенный clus teringC. Индекс Rand, который может быть использован: он выражает вероятность того, что для случайно выбранной пары экземпляров R и C согласуются в том, находятся ли они в одном кластере или нет. Когда R = C, индекс Rand равен 1. Для случайной кластеризации in dex не равен нулю. По этой причине часто отдают предпочтение «скорректированному индексу Рэнда» (ARI): он перемасштабирует индекс Рэнда таким образом, что ожидаемый ARI случайной кластеризации равен 0.
## 7.5 What are the limitations of learning? Каковы ограничения обучения?
Используй ML только когда это нужно. Нет смысла решать через ML, если известно решение задачи  

Пусть нужно составить расписание защиты дипломов в университете.
У нас есть данные: какие работы должны быть защищены, какие профессора оценивают какие работы, расписания студентов и преподавателей, доступность аудиторий и пр.
Некоторые ограничения очевидны: профессор не может находиться в двух местах одновременно, две защиты не могут быть в одной аудитории в одно и то же время.
Но есть и неявные ограничения:
— аудитории могут быть слишком далеко друг от друга,
— некоторые преподаватели не работают после 18:00.
Пользователь может не знать обо всех таких ограничениях, но программа может их "выучить" из прошлых расписаний, выявив закономерности.


* Выбор подхода машинного обучения зависит:

  * от типа задачи (классификация, регрессия и т.д.),
  * от операционных ограничений (например, требований к интерпретируемости или энергоэффективности),
  * от свойств датасета:
    * какие методы лучше работают с высокомерными данными,
    * какие — более вычислительно эффективны, и так далее.


* Каждый метод машинного обучения имеет так называемый индуктивный сдвиг (inductive bias) — это набор неявных предположений о целевой модели.
Метод будет работать хорошо, если его индуктивный сдвиг соответствует задаче.

Проблема:
- мы плохо понимаем индуктивные сдвиги многих алгоритмов,
- и также не всегда ясно, какой сдвиг подходит для конкретного датасета.

**Простой пример:**  
Моделируем зависимость зарплаты академика от должности, возраста, пола и страны проживания.
* Линейная регрессия предполагает аддитивность эффектов: если увеличение переменной x₁ увеличивает y на v₁, а x₂ — на v₂, то обе вместе увеличат y на v₁+v₂.
  * Это означает, например, что разница в зарплате между мужчинами и женщинами одинакова во всех странах — что может быть нереалистично.

  * Решающее дерево не делает таких предположений: оно может разделить данные по стране и строить отдельные модели для каждой.
  * Минус: данные в каждой группе становятся меньше, и точность падает, потому что модели обучаются на маленьких выборках.

* На этом фоне может показаться, что стоит разработать алгоритмы без индуктивного сдвига — универсальные.
Но это невозможно.

* Существуют т.н. "теоремы об отсутствии бесплатного обеда" (no-free-lunch theorems) — они показывают, что обучение без какого-либо индуктивного сдвига невозможно в принципе.

* Даже стремление к "минимальному сдвигу" неэффективно:
* Алгоритмы с сильным индуктивным сдвигом будут всегда работать лучше на задачах, которые этому сдвигу соответствуют.

## 7.6 Industry examples
### 7.6.1 Predicting the metallization rate in iron production using ensemble methods at ArcelorMittal
* Многие промышленные процессы, требующие регуляции петли обратной связи, могут извлечь выгоду из суперконтролируемых алгоритмов машинного обучения. Фактически, состояние и параметры процесса могут быть переданы регрессионным моделям для прогнозирования будущего состояния и, следовательно, для точного применения дополнительных параметров, необходимых для оптимизации результата. Одним из таких процессов является прямое восстановление чугуна на сталелитейных заводах: примеси в реагентах добавляют степень изменчивости, что требует периодической корректировки условий химического процесса с целью увеличения скорости металлизации и, следовательно, получения стали более высокого качества.
* Наиболее важным показателем производительности установки прямого восстановления является «коэффициент метелизации», то есть чистота чугуна, которая, в свою очередь, определяет качество и эффективность стали на последующих этапах. Таким образом, операторы должны поддерживать металлизацию на самом высоком уровне, с минимальным отклонением по всем входным переменным, с максимальной производительностью и минимальным потреблением энергии. Для определения скорости металлизации производственные образцы регулярно доставляются в лабораторию и проходят 2-часовой процесс анализа
* Плавка может 2 часа идти не по правилу и только потом начнутся действия по исправлению
* Модель ИИ улучшила качество продукции, снизила энергопотребление, увеличила прибыль компании
* Каждые 30 секунд собираются данные, предсказывается не то, как быстро будет идти метализация, а как она изменится относительно текущего
* Всего используется более 60 предикторов, а для обучения моделей машинного обучения было доступно данных за 2 года. После предварительной обработки данных были оценены предикторы на основе корреляции между парами предикторов.
* 4 модели: Linear Lasso, LGBM, Gradient Boosting и Random Forests 
* Обучение с целью минимизации среднеабсолютной погрешности скорости металлизации






### текстииль
Решение, предоставленное Robovision и Viu More, позволяет автоматически выявлять дефекты и оценивать качество текстиля на метр. Используемые методы позволяют в режиме реального времени контролировать текстиль шириной 2 метра с помощью трех 12-мегапиксельных камер, работающих на протяжении всего производственного процесса. Выявляются пять классов дефектов, показанных ниже, и каждой части текстиля присваивается оценка качества. Проблема разделяется на две задачи без учителя, где дефекты сначала обнаруживаются, а затем оценки качества присваиваются каждой части списка, и контролируемая задача, где выделенные дефекты классифицируются по одному из пяти вышеупомянутых дефектов. Ключевой частью комплексного решения является алгоритм обнаружения аномалий без учителя, обученный на изображениях хорошего текстиля. Получить изображение хорошего текстиля значительно проще, так как известно, что дефекты встречаются редко.
чаще инфа о хорошем текстиле